{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57b24959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mne_nirs\n",
    "import mne\n",
    "from mne_bids import BIDSPath, get_entity_vals\n",
    "from mne.preprocessing.nirs import optical_density, temporal_derivative_distribution_repair\n",
    "from itertools import compress\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64b55b",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6ed3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_preprocessing(subject_index, t_min,t_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Subject index: int = Index of the subject to be processed [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    t_min: float =  Time to initialize the epoch\n",
    "    t_max: float = Time to end the epoch\n",
    "    \n",
    "    Returns:\n",
    "    haemo:= The preprocessed haemoglobin data\n",
    "    epochs: mne.Epochs object = The preprocessed epochs. You can use this to get the data and labels for the classification task.\n",
    "    X: np.array = The preprocessed data. Shape: (n_trials, n_channels, n_times)\n",
    "    Y: np.array = The labels for the classification task. Shape: (n_trials,)\n",
    "    Y labels : 1.0-> Audio, 3.0 -> Control (Silence)\n",
    "    \"\"\"\n",
    "    \n",
    "    root = mne_nirs.datasets.audio_or_visual_speech.data_path()\n",
    "    \n",
    "    print(root)\n",
    "    \n",
    "    subject= get_entity_vals(root, \"subject\")[subject_index]\n",
    "   \n",
    "        \n",
    "    dataset = BIDSPath(\n",
    "            root=root,\n",
    "            suffix=\"nirs\",\n",
    "            extension=\".snirf\",\n",
    "            subject=subject,\n",
    "            task=\"AudioVisualBroadVsRestricted\",\n",
    "            datatype=\"nirs\",\n",
    "            session=\"01\"\n",
    "                            )\n",
    "                \n",
    "    #Raw intensity data\n",
    "    raw_intensity = mne.io.read_raw_snirf(dataset.fpath)\n",
    "    \n",
    "    raw_intensity.annotations.rename(\n",
    "        {\"1.0\": \"Audio\", \"2.0\": \"Video\", \"3.0\": \"Control\", \"15.0\": \"Ends\"}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Converting raw intensity to optical density\n",
    "    raw_od = optical_density(raw_intensity)\n",
    "\n",
    "\n",
    "    #Compute scalp coupling index to identify optodes that were not well attached to the scalp\n",
    "    #Rejection criterion of < 0.8\n",
    "    sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)\n",
    "    raw_od.info[\"bads\"] = list(compress(raw_od.ch_names, sci < 0.8))\n",
    "    \n",
    "    print(\"Number of channels before removing bad channels: \", len(raw_od.ch_names))\n",
    "    #raw_od = raw_od.info.pop('bads')\n",
    "\n",
    "    raw_od = raw_od.drop_channels(raw_od.info['bads'])\n",
    "\n",
    "    print(\"Number of channels after removing bad channels: \", len(raw_od.ch_names))\n",
    "        \n",
    "\n",
    "    #Temporal Derivative Distribution Repair\n",
    "    \n",
    "    corrected_tddr = temporal_derivative_distribution_repair(raw_od)\n",
    "    \n",
    "    #Apply short channel correction  to remove the influence from non-cortical changes in blood oxygenation.\n",
    "    \n",
    "    # A short separation channels measures solely the extracerebral signals, which includes \n",
    "    # blood presure waves, mayer waves, respiration and cardiac cycles.\n",
    "    # The signal components od the short separation channel can be seen as the noise in the signal of the \n",
    "    # long channel.BY removing these components from the log channel, you cna minimize the noise.\n",
    "    \n",
    "    \n",
    "    od_corrected = mne_nirs.signal_enhancement.short_channel_regression(corrected_tddr)\n",
    "    #Convert optical density to haemoglobin concentration using the Beer-Lambert Law\n",
    "    haemo = mne.preprocessing.nirs.beer_lambert_law(od_corrected, ppf=6)\n",
    "    \n",
    "    haemo = mne_nirs.channels.get_long_channels(haemo)\n",
    "    \n",
    "    #Bandpass filter the haemoglobin data between 0.02 and 0.4 Hz\n",
    "    #to removoe slow drifts and components related to the heart rate\n",
    "    haemo = haemo.filter(0.02,0.4)\n",
    "    \n",
    "    #Signal enhancement method (negative correlation enhancement algorithm) Cui et. al. 2010\n",
    "    \n",
    "    haemo = mne_nirs.signal_enhancement.enhance_negative_correlation(haemo)\n",
    "    \n",
    "\n",
    "        \n",
    "    events, event_dict = mne.events_from_annotations(haemo)\n",
    "    \n",
    "    #An epoch rejection criterion  was employed to exclude epochs with a signal amplitude > 100 uM\n",
    "    epochs = mne.Epochs(\n",
    "        haemo,\n",
    "        events,\n",
    "        event_id=event_dict,\n",
    "        tmin=t_min,\n",
    "        tmax=t_max,\n",
    "        reject=dict(hbo=100e-6, hbr=100e-6), # Epoc rejection criterion\n",
    "        reject_by_annotation=True,\n",
    "        proj=False,\n",
    "        baseline=None,\n",
    "        detrend=None,\n",
    "        preload=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    # I am just selecting the Audio and Control epochs\n",
    "    epochs = epochs[[\"Audio\", \"Control\"]]\n",
    "    \n",
    "    return haemo, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73ee200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_data(subject_index, t_min, t_max):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    subject_index: int = Index of the subject to be processed [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    t_min: float =  Time to initialize the epoch\n",
    "    t_max: float = Time to end the epoch\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    X: np.array = The preprocessed data. Shape: (n_trials, n_channels, n_times)\n",
    "    Y: np.array = The labels for the classification task. Shape: (n_trials,)\n",
    "    Y labels : 1.0-> Audio, 3.0 -> Control (Silence)\n",
    "    \"\"\"\n",
    "    \n",
    "    haemo, epochs = epoch_preprocessing(subject_index, t_min, t_max)\n",
    "    \n",
    "    X = epochs.get_data()\n",
    "    Y = epochs.events[:, 2]\n",
    "    print(\"Shape of the data: \", X.shape)\n",
    "    print(\"Shape of the labels: \", Y.shape)\n",
    "\n",
    "    # Change the labels to 0 and 1\n",
    "    Y = (Y == 1).astype(int)\n",
    "\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938328f4",
   "metadata": {},
   "source": [
    "## Train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0936dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import (KFold, StratifiedKFold, StratifiedGroupKFold,\n",
    "                                     GridSearchCV, train_test_split)\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             confusion_matrix)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,EditedNearestNeighbours\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd60218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning_exp(model,X,Y,output_folder,dataset,sampling):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function train SVM, LDA and KNN models with nested cross-validation.\n",
    "    \n",
    "    The outer cross-validation  with 5 folds is used to evaluate the model performance, while the inner \n",
    "    cross-validation with 3 folds is used to tune the hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        The model to be used. Can be 'svc', 'lda' or 'knn'.\n",
    "    X : np.array\n",
    "        The features to be used for training and testing the model. shape (n_trials, n_channels, n_timepoints)\n",
    "    Y : np.array\n",
    "        The labels to be used for training and testing the model.\n",
    "    output_folder : str\n",
    "        The folder where the results will be saved.\n",
    "    dataset : str\n",
    "        The name of the dataset. Can be 'audio_study'. \n",
    "        \n",
    "    sampling : str\n",
    "        The sampling method to be used. Can be 'Random_over', 'SMOTE', 'ADASYN', 'BorderlineSmote', \n",
    "        'Random_under'\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    accuracies : list\n",
    "        The accuracies of the model on the test sets.\n",
    "    all_hps : list\n",
    "        The best hyperparameters of the model on the test sets.\n",
    "    auc : list\n",
    "        The AUC of the model on the test sets.\n",
    "    svc_coeff : list\n",
    "        The coefficients of the learned features from the SVC model or LDA model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # outer and inner cross-validation parameters\n",
    "    OUTER_K = 5\n",
    "    INNER_K = 3\n",
    "    SEED = 22\n",
    "\n",
    "    # Standard machine learning parameters\n",
    "    MAX_ITER = 250000  # for support vector classifier\n",
    "    \n",
    "    # Regularization parameters values tested for the SVC\n",
    "    C_LIST = [1e-3, 1e-2, 1e-1, 1e0]\n",
    "    # Number of neighbors values tested for the KNN\n",
    "    N_NEIGHBORS_LIST = list(range(1, 10))\n",
    "\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    accuracies = []\n",
    "    additional_metrics = []\n",
    "    all_hps = []\n",
    "    auc = []\n",
    "    \n",
    "    svc_coeff =[]\n",
    "    lda_coeff = []\n",
    "\n",
    "    out_kf = StratifiedKFold(n_splits=OUTER_K,shuffle=True,random_state=SEED)\n",
    "    in_kf = StratifiedKFold(n_splits=INNER_K,shuffle=True,random_state=SEED)\n",
    "\n",
    "    out_split = out_kf.split(X, Y)\n",
    "\n",
    "    for k, out_idx in enumerate(out_split):\n",
    "        \n",
    "        print(f'Outer fold {k+1}/{OUTER_K}')\n",
    "        X_train, X_test = X[out_idx[0]], X[out_idx[1]]\n",
    "        Y_train, Y_test = Y[out_idx[0]], Y[out_idx[1]]\n",
    "        \n",
    "        X_train, Y_train = shuffle(X_train, Y_train, random_state=SEED)\n",
    "        \n",
    "        all_y_true.extend(Y_test)\n",
    "        \n",
    "        \n",
    "        #Normalize \n",
    "        \n",
    "        maxs = X_train.max(axis =(0,2),keepdims=True)\n",
    "        mins = X_train.min(axis =(0,2),keepdims=True)\n",
    "        \n",
    "        X_train = (X_train - mins)/(maxs-mins)\n",
    "        X_test = (X_test - mins)/(maxs-mins)\n",
    "        \n",
    "        X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "        X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "        \n",
    "        \n",
    "        if dataset =='audio_study':\n",
    "    \n",
    "        \n",
    "            if sampling == 'Random_over':\n",
    "                \n",
    "                print(\"Random Oversampling\")\n",
    "                \n",
    "                ros = RandomOverSampler(random_state=SEED)\n",
    "                X_train,Y_train = ros.fit_resample(X_train, Y_train)\n",
    "                \n",
    "            elif sampling == 'SMOTE':\n",
    "                \n",
    "                print(\"Smote Oversampling\")\n",
    "                \n",
    "                X_train, Y_train = SMOTE().fit_resample(X_train,Y_train)\n",
    "                \n",
    "            elif sampling == 'ADASYN':\n",
    "                \n",
    "                print(\"ADASYN Oversampling\")\n",
    "                \n",
    "                X_train, Y_train = ADASYN().fit_resample(X_train,Y_train)\n",
    "                \n",
    "            elif sampling =='BorderlineSmote':\n",
    "                \n",
    "                print(\"BorderlineSmote Oversampling\")\n",
    "                \n",
    "                X_train, Y_train = BorderlineSMOTE.fit_resample(X_train,Y_train)\n",
    "                \n",
    "            elif sampling=='Random_under':\n",
    "                \n",
    "                print(\"Random Undersampling\")\n",
    "                \n",
    "                rus = RandomUnderSampler(random_state=SEED)\n",
    "                \n",
    "                X_train, Y_train = rus.fit_resample(X_train,Y_train)\n",
    "                \n",
    "            elif sampling == 'EditedNearesNeighbours':\n",
    "                \n",
    "                print(\"Edited Nearest Neighbours undersampling\")\n",
    "                \n",
    "                enn = EditedNearestNeighbours()\n",
    "                \n",
    "                X_train, Y_train = enn.fit_resample(X_train,Y_train)\n",
    "                \n",
    "            elif sampling == 'No':\n",
    "                \n",
    "                print(\"No sampling method applied\")\n",
    "                \n",
    "                X_train,Y_train = X_train, Y_train\n",
    "\n",
    "        # Inner CV\n",
    "        \n",
    "        in_split = in_kf.split(X_train, Y_train)\n",
    "        \n",
    "        if model == 'lda':\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            lda.fit(X_train, Y_train)\n",
    "            lda_coeff.append(lda.coef_)\n",
    "            y_pred = lda.predict(X_test).tolist()\n",
    "            all_hps.append(None)\n",
    "            \n",
    "        elif model=='knn':\n",
    "            parameters = {'n_neighbors': N_NEIGHBORS_LIST}\n",
    "            knn = KNeighborsClassifier()\n",
    "            clf = GridSearchCV(knn, parameters,scoring = 'accuracy', cv=in_split)\n",
    "            clf.fit(X_train,Y_train)\n",
    "            y_pred = clf.predict(X_test).tolist()\n",
    "            \n",
    "            all_hps.append(clf.best_params_['n_neighbors'])\n",
    "            \n",
    "        elif model=='svc':\n",
    "            parameters = {'C': C_LIST}\n",
    "            svc = LinearSVC(max_iter=MAX_ITER, dual='auto')\n",
    "            clf = GridSearchCV(svc, parameters,scoring = 'accuracy', cv=in_split)\n",
    "            clf.fit(X_train,Y_train)\n",
    "            best_svc= clf.best_estimator_\n",
    "            svc_coeff.append(best_svc.coef_)\n",
    "            print(\"number of features seen during fit:\", best_svc.n_features_in_)\n",
    "            y_pred = clf.predict(X_test).tolist()\n",
    "            \n",
    "            all_hps.append(clf.best_params_['C'])\n",
    "        \n",
    "            \n",
    "            \n",
    "        # Metrics\n",
    "        accuracies.append(accuracy_score(Y_test, y_pred))\n",
    "        auc.append(roc_auc_score(Y_test, y_pred))\n",
    "        prfs = precision_recall_fscore_support(Y_test, y_pred)\n",
    "        additional_metrics.append(prfs)\n",
    "        all_y_pred += y_pred\n",
    "        \n",
    "\n",
    "    # Figures\n",
    "    cm = confusion_matrix(all_y_true, all_y_pred, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, cmap='crest', vmin=0.1, vmax=0.8)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground truth')\n",
    "    plt.title('Confusion matrix on the test sets')\n",
    "    plt.savefig(f'{output_folder}/confusion_matrix_{model}.png')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    return accuracies, all_hps, auc,svc_coeff,lda_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188a284",
   "metadata": {},
   "source": [
    "## Main cell to train models and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6aabac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(os.getcwd(), '0_18')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "CONFIDENCE = 0.05  # stat confidence at 95 %\n",
    "\n",
    "SEED = 22\n",
    "sampling = 'ADASYN'\n",
    "\n",
    "dict_accuracies = {}\n",
    "subjects = [0]\n",
    "\n",
    "\n",
    "t_min = 0.0 # ONSET\n",
    "t_max = 18.0 # END\n",
    "\n",
    "classes = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4e403e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio_study dataset\n",
      "/home/sposso22/mne_data/fNIRS-audio-visual-speech\n",
      "Loading /home/sposso22/mne_data/fNIRS-audio-visual-speech/sub-01/ses-01/nirs/sub-01_ses-01_task-AudioVisualBroadVsRestricted_nirs.snirf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 7976  =      0.000 ...  2041.856 secs...\n",
      "Number of channels before removing bad channels:  104\n",
      "Number of channels after removing bad channels:  90\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.02 - 0.4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.02\n",
      "- Lower transition bandwidth: 0.02 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 0.40 Hz\n",
      "- Upper transition bandwidth: 1.55 Hz (-6 dB cutoff frequency: 1.18 Hz)\n",
      "- Filter length: 645 samples (165.120 s)\n",
      "\n",
      "Used Annotations descriptions: [np.str_('Audio'), np.str_('Control'), np.str_('Ends'), np.str_('Video')]\n",
      "Not setting metadata\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 48 events and 71 original time points ...\n",
      "0 bad epochs dropped\n",
      "Shape of the data:  (28, 76, 71)\n",
      "Shape of the labels:  (28,)\n",
      "X shape (28, 76, 71)\n",
      "Outer fold 1/5\n",
      "ADASYN Oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features seen during fit: 5396\n",
      "Outer fold 2/5\n",
      "ADASYN Oversampling\n",
      "number of features seen during fit: 5396\n",
      "Outer fold 3/5\n",
      "ADASYN Oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sposso22/miniconda3/envs/fNIRS_spatial_temp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features seen during fit: 5396\n",
      "Outer fold 4/5\n",
      "ADASYN Oversampling\n",
      "number of features seen during fit: 5396\n",
      "Outer fold 5/5\n",
      "ADASYN Oversampling\n",
      "number of features seen during fit: 5396\n",
      "Outer fold 1/5\n",
      "ADASYN Oversampling\n",
      "Outer fold 2/5\n",
      "ADASYN Oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sposso22/miniconda3/envs/fNIRS_spatial_temp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 3/5\n",
      "ADASYN Oversampling\n",
      "Outer fold 4/5\n",
      "ADASYN Oversampling\n",
      "Outer fold 5/5\n",
      "ADASYN Oversampling\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    \n",
    "    audio_folder = os.path.join(out_folder,f'_folder_subj_{subject}')\n",
    "    os.makedirs(audio_folder, exist_ok=True)\n",
    "    \n",
    "    lda_coeff_path = os.path.join(out_folder,f'_lda_coeff_{subject}')\n",
    "    os.makedirs(lda_coeff_path, exist_ok=True)\n",
    "    \n",
    "    DATASETS = {'audio_study': [t_min,t_max]}\n",
    "    \n",
    "    with open(f'{audio_folder}/summary_subj_{subject}.md', 'w') as w:\n",
    "        w.write('# AUC table\\n\\n(Standard deviation on the cross-validation)')\n",
    "        w.write('\\n\\n|Dataset|Chance level|')\n",
    "        w.write('LDA (sd)|SVC (sd)|\\n')\n",
    "        w.write('|:---:|:---:|:---:|:---:|:---:|:---:|\\n')\n",
    "    with open(f'{audio_folder}/results_subj_{subject}.csv', 'w') as w:\n",
    "        w.write('dataset;model;fold;AUC;hyperparameters\\n')\n",
    "        \n",
    "    for dataset in DATASETS.keys():\n",
    "        print(f'Processing {dataset} dataset')\n",
    "        params = DATASETS[dataset]\n",
    "\n",
    "        \n",
    "        if dataset == 'audio_study':\n",
    "            t_min, t_max = params\n",
    "\n",
    "            X,Y= audio_data(subject,t_min,t_max)\n",
    "            #X = X[:,:,int(3.9*abs(t_min)):]\n",
    "            print(\"X shape\", X.shape)\n",
    "            \n",
    "            \n",
    "\n",
    "        _, hps_svc,svc,svc_coeff,_ = machine_learning_exp(\"svc\",X,Y,audio_folder,dataset,sampling)\n",
    "        _, hps_lda,lda,_,lda_coeff = machine_learning_exp(\"lda\", X, Y, audio_folder,dataset,sampling)\n",
    "        #_, hps_knn,knn,_,_= machine_learning_exp(\"knn\", X, Y,audio_folder,dataset,sampling)\n",
    "        \n",
    "        \n",
    "        #Saving the coefficients of the trained models\n",
    "        np.savez(audio_folder, folder_1 = svc_coeff[0],folder_2 = svc_coeff[1],\n",
    "                 folder_3 = svc_coeff[2], folder_4 = svc_coeff[3], folder_5= svc_coeff[4])\n",
    "        \n",
    "        np.savez(lda_coeff_path, folder_1 = lda_coeff[0],folder_2 = lda_coeff[1],\n",
    "                 folder_3 = lda_coeff[2], folder_4 = lda_coeff[3], folder_5= lda_coeff[4])\n",
    "    \n",
    "        results = {'LDA': [lda, hps_lda], 'SVC': [svc, hps_svc]}\n",
    "        \n",
    "        chance_level = np.around(1/classes, decimals=3)\n",
    "        w_summary = open(f'{audio_folder}/summary_subj_{subject}.md', 'a')\n",
    "        w_results = open(f'{audio_folder}/results_subj_{subject}.csv', 'a')\n",
    "        w_summary.write(f'|{dataset}|{chance_level}|')\n",
    "        for model in results.keys():\n",
    "            w_summary.write(\n",
    "                f'{np.around(np.mean(results[model][0]), decimals=3)} '\n",
    "                f'({np.around(np.std(results[model][0]), decimals=3)})|')\n",
    "            for fold, auc in enumerate(results[model][0]):\n",
    "                hps = results[model][1][fold]\n",
    "                w_results.write(f'{dataset};{model};{fold+1};{auc};\"{hps}\"\\n')\n",
    "        w_summary.write('\\n')\n",
    "        w_summary.close()\n",
    "        w_results.close()\n",
    "        dict_accuracies[dataset] = lda + svc \n",
    "\n",
    "    dict_accuracies['Model'] = list(np.repeat(list(results.keys()), len(lda)))\n",
    "    df_accuracies = pd.DataFrame(dict_accuracies)\n",
    "    df_accuracies = df_accuracies.melt(\n",
    "        id_vars=['Model'], value_vars=list(DATASETS.keys()),\n",
    "        var_name='Dataset', value_name='AUC')\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.barplot(data=df_accuracies, y='AUC', x='Dataset', hue='Model',\n",
    "                capsize=.1, palette='colorblind')\n",
    "    plt.axhline(1/2, color='blue', linestyle=':', label='2 classes chance level')\n",
    "    plt.legend(bbox_to_anchor=(1.01, 0.5), loc=6)\n",
    "    plt.savefig(f'{audio_folder}/summary.png', bbox_inches='tight', dpi=1200)\n",
    "    plt.close()\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65bcab",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fe07c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Adjust the width and height as needed\n",
    "plt.imshow(mpimg.imread(\"0_18/_folder_subj_0/summary.png\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "842bf40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AUC table\n",
      "\n",
      "(Standard deviation on the cross-validation)\n",
      "\n",
      "|Dataset|Chance level|LDA (sd)|SVC (sd)|\n",
      "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "|audio_study|0.5|0.792 (0.167)|0.758 (0.172)|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md_file_path = \"0_18/_folder_subj_0/summary_subj_0.md\"\n",
    "\n",
    "# Open and read the file\n",
    "with open(md_file_path, 'r') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "# Print the content\n",
    "print(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051e71f",
   "metadata": {},
   "source": [
    "### Results from each outer cross-validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5d24c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dataset model  fold       AUC  hyperparameters\n",
      "0  audio_study   LDA     1  0.875000              NaN\n",
      "1  audio_study   LDA     2  0.500000              NaN\n",
      "2  audio_study   LDA     3  0.750000              NaN\n",
      "3  audio_study   LDA     4  0.833333              NaN\n",
      "4  audio_study   LDA     5  1.000000              NaN\n",
      "5  audio_study   SVC     1  0.875000            0.100\n",
      "6  audio_study   SVC     2  0.500000            0.010\n",
      "7  audio_study   SVC     3  0.750000            0.001\n",
      "8  audio_study   SVC     4  0.666667            0.010\n",
      "9  audio_study   SVC     5  1.000000            0.100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv = pd.read_csv(\"0_18/_folder_subj_0/results_subj_0.csv\", sep=';')\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76374b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fNIRS_spatial_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
